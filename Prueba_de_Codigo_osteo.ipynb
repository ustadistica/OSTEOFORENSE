{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McO2GDAT438C",
        "outputId": "607365fd-a296-459e-ec19-4f4440081a5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.12/dist-packages (0.10.21)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.12/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (25.3.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (25.2.10)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.5.3)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from mediapipe) (3.10.0)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (1.26.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.12/dist-packages (from mediapipe) (4.11.0.86)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (4.25.8)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.5.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.2.1)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.12/dist-packages (from sounddevice>=0.4.4->mediapipe) (2.0.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe) (0.5.3)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe) (1.16.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (4.60.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (3.2.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.23)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install mediapipe opencv-python-headless\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import mediapipe as mp\n",
        "from google.colab import files\n",
        "import os\n",
        "from datetime import datetime\n",
        "import json\n",
        "from PIL import Image\n",
        "import math\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# Conexión con Google Drive y preparación de carpetas del proyecto\n",
        "# ============================================================================\n",
        "\n",
        "import os\n",
        "\n",
        "try:\n",
        "    # Conectar Google Colab con tu Google Drive\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')  # Se abrirá una ventana para autorizar el acceso\n",
        "\n",
        "    # Ruta principal del proyecto en Drive\n",
        "    proyecto_path = \"/content/drive/MyDrive/Analisis_Osteoforense\"\n",
        "\n",
        "    # Crear carpetas del proyecto si no existen\n",
        "    os.makedirs(os.path.join(proyecto_path, \"imagenes\"), exist_ok=True)\n",
        "    os.makedirs(os.path.join(proyecto_path, \"resultados\"), exist_ok=True)\n",
        "\n",
        "    # Mensajes para confirmar\n",
        "    print(\"Google Drive se ha montado correctamente.\")\n",
        "    print(f\"Carpeta principal del proyecto: {proyecto_path}\")\n",
        "\n",
        "except Exception as e:\n",
        "    # Si algo falla, trabajamos en almacenamiento local\n",
        "    print(\"No se pudo montar Google Drive. Se usará almacenamiento local.\")\n",
        "    print(f\"Detalles del error: {e}\")\n",
        "\n",
        "    # Ruta alternativa en el entorno local de Colab\n",
        "    proyecto_path = \"/content/Analisis_Osteoforense\"\n",
        "\n",
        "    # Crear carpetas locales si no existen\n",
        "    os.makedirs(os.path.join(proyecto_path, \"imagenes\"), exist_ok=True)\n",
        "    os.makedirs(os.path.join(proyecto_path, \"resultados\"), exist_ok=True)\n",
        "\n",
        "    print(f\"Carpeta local creada: {proyecto_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxyKfSMq5gZT",
        "outputId": "a1177177-4e2d-4294-c595-a610e3cf6a75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Google Drive se ha montado correctamente.\n",
            "Carpeta principal del proyecto: /content/drive/MyDrive/Analisis_Osteoforense\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# Configuración de MediaPipe Face Mesh para análisis osteoforense\n",
        "# ============================================================================\n",
        "\n",
        "import mediapipe as mp  # Asegúrate de haberlo importado antes\n",
        "\n",
        "# --- 1️Configurar el modelo Face Mesh ---\n",
        "# static_image_mode=True  → Procesa imágenes estáticas (no video)\n",
        "# max_num_faces=1         → Solo detecta un rostro\n",
        "# refine_landmarks=True   → Más precisión en ojos, labios y cejas\n",
        "# min_detection_confidence=0.5 → Confianza mínima para detección\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "face_mesh = mp_face_mesh.FaceMesh(\n",
        "    static_image_mode=True,\n",
        "    max_num_faces=1,\n",
        "    refine_landmarks=True,\n",
        "    min_detection_confidence=0.5\n",
        ")\n",
        "\n",
        "# --- 2️Mapeo de landmarks osteoforenses ---\n",
        "# Diccionario que relaciona los puntos anatómicos clave con sus índices en MediaPipe\n",
        "LANDMARK_MAPPING = {\n",
        "    'glabella': 9,          # Punto más prominente de la frente\n",
        "    'nasion': 6,            # Raíz nasal entre cejas\n",
        "    'pronasale': 2,         # Punta de la nariz\n",
        "    'subnasale': 2,         # Base de la nariz\n",
        "    'pogonion': 175,        # Punto más anterior del mentón\n",
        "    'gnathion': 18,         # Punto más inferior de la barbilla\n",
        "    'endocanthion_L': 133,  # Canto interno del ojo izquierdo\n",
        "    'endocanthion_R': 362,  # Canto interno del ojo derecho\n",
        "    'ectocanthion_L': 33,   # Canto externo del ojo izquierdo\n",
        "    'ectocanthion_R': 263,  # Canto externo del ojo derecho\n",
        "    'alare_L': 129,         # Ala nasal izquierda\n",
        "    'alare_R': 358,         # Ala nasal derecha\n",
        "    'cheilion_L': 61,       # Comisura labial izquierda\n",
        "    'cheilion_R': 291,      # Comisura labial derecha\n",
        "    'labiale_superius': 13, # Punto medio del labio superior\n",
        "    'labiale_inferius': 14, # Punto medio del labio inferior\n",
        "    'stomion': 12,          # Contacto entre los labios\n",
        "    'zygion_L': 116,        # Punto lateral del pómulo izquierdo\n",
        "    'zygion_R': 345,        # Punto lateral del pómulo derecho\n",
        "    'gonion_L': 172,        # Ángulo mandibular izquierdo\n",
        "    'gonion_R': 397         # Ángulo mandibular derecho\n",
        "}\n",
        "\n",
        "# --- 3️Definición de medidas osteoforenses ---\n",
        "# Cada entrada: abreviatura : (punto1, punto2, descripción)\n",
        "MEDIDAS_OSTEOFORENSES = {\n",
        "    'g_n': ('glabella', 'nasion', 'Altura glabelar'),\n",
        "    'n_prn': ('nasion', 'pronasale', 'Longitud dorso nasal'),\n",
        "    'n_sn': ('nasion', 'subnasale', 'Altura nasal total'),\n",
        "    'sn_pg': ('subnasale', 'pogonion', 'Altura tercio inferior'),\n",
        "    'g_gn': ('glabella', 'gnathion', 'Altura facial total'),\n",
        "    'al_al': ('alare_L', 'alare_R', 'Ancho nasal'),\n",
        "    'en_en': ('endocanthion_L', 'endocanthion_R', 'Distancia intercanthal'),\n",
        "    'ex_ex': ('ectocanthion_L', 'ectocanthion_R', 'Distancia bi-ectocanthal'),\n",
        "    'ch_ch': ('cheilion_L', 'cheilion_R', 'Ancho de boca'),\n",
        "    'zy_zy': ('zygion_L', 'zygion_R', 'Ancho bizigomático'),\n",
        "    'go_go': ('gonion_L', 'gonion_R', 'Ancho bigonial'),\n",
        "    'ojo_izquierdo': ('endocanthion_L', 'ectocanthion_L', 'Ancho ojo izquierdo'),\n",
        "    'ojo_derecho': ('endocanthion_R', 'ectocanthion_R', 'Ancho ojo derecho'),\n",
        "    'ls_li': ('labiale_superius', 'labiale_inferius', 'Altura labial'),\n",
        "    'sn_sto': ('subnasale', 'stomion', 'Altura labio superior')\n",
        "}\n",
        "\n",
        "# --- 4️Mensajes informativos ---\n",
        "print(\"Configuración de MediaPipe completada.\")\n",
        "print(f\"Landmarks definidos: {len(LANDMARK_MAPPING)}\")\n",
        "print(f\"Medidas osteoforenses a calcular: {len(MEDIDAS_OSTEOFORENSES)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4B_ti8Cx53Ps",
        "outputId": "524c62d6-0b01-477d-d7d5-a20d7cf03caf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuración de MediaPipe completada.\n",
            "Landmarks definidos: 21\n",
            "Medidas osteoforenses a calcular: 15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# FUNCIÓN: CARGAR IMAGEN PARA ANÁLISIS\n",
        "# ============================================================================\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "def cargar_imagen():\n",
        "    \"\"\"\n",
        "    Permite subir una imagen desde tu dispositivo y la prepara\n",
        "    para su análisis con OpenCV.\n",
        "\n",
        "    Retorna:\n",
        "        imagen (ndarray): Imagen en formato OpenCV (BGR)\n",
        "        filename (str): Nombre del archivo cargado\n",
        "    \"\"\"\n",
        "    # --- 1️Solicitar al usuario subir una imagen ---\n",
        "    print(\"PASO 1: Cargar imagen para análisis\")\n",
        "    print(\"Selecciona la imagen que deseas analizar:\")\n",
        "\n",
        "    uploaded = files.upload()  # Abre selector de archivos en Colab\n",
        "\n",
        "    if not uploaded:\n",
        "        print(\"No se subió ninguna imagen.\")\n",
        "        return None, None\n",
        "\n",
        "    # --- 2️Obtener datos del archivo cargado ---\n",
        "    filename = list(uploaded.keys())[0]           # Nombre del archivo\n",
        "    image_data = uploaded[filename]               # Datos binarios\n",
        "\n",
        "    # --- 3️Convertir a formato OpenCV ---\n",
        "    nparr = np.frombuffer(image_data, np.uint8)\n",
        "    imagen = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
        "\n",
        "    if imagen is None:\n",
        "        print(\"Error al decodificar la imagen.\")\n",
        "        return None, None\n",
        "\n",
        "    # --- 4️Mostrar información de la imagen ---\n",
        "    alto, ancho, canales = imagen.shape\n",
        "    print(\"Imagen cargada exitosamente.\")\n",
        "    print(f\"   📏 Dimensiones: {ancho} x {alto} píxeles\")\n",
        "    print(f\"Archivo: {filename}\")\n",
        "\n",
        "    # --- 5️⃣ Guardar imagen en carpeta del proyecto ---\n",
        "    # (Se usa un hash o nombre fijo, puedes personalizarlo)\n",
        "    hash_imagen = \"0aad2507592c642223603f2e46cf1bdc601f8136fd5e7a4cc4cec59f844a68b5\"\n",
        "    ruta_guardado = f\"{proyecto_path}/imagenes/{hash_imagen}.jpg\"\n",
        "    cv2.imwrite(ruta_guardado, imagen)\n",
        "    print(f\"Imagen guardada en: {ruta_guardado}\")\n",
        "\n",
        "    return imagen, filename\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "pi4yQmIk6Ltl",
        "outputId": "8d1c63ad-1e2f-49a3-8c3e-a030ec471d96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unexpected indent (ipython-input-3711120671.py, line 8)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-3711120671.py\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    uploaded = files.upload()  # Abre selector de archivos en Colab\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "#  FUNCIÓN: DETECTAR LANDMARKS FACIALES CON MEDIAPIPE\n",
        "# ============================================================================\n",
        "\n",
        "def detectar_landmarks(imagen):\n",
        "    \"\"\"\n",
        "    Detecta los landmarks faciales de una imagen usando MediaPipe Face Mesh.\n",
        "\n",
        "    Parámetros:\n",
        "        imagen (ndarray): Imagen en formato OpenCV (BGR)\n",
        "\n",
        "    Retorna:\n",
        "        dict: Diccionario con coordenadas en píxeles de cada landmark definido\n",
        "              en LANDMARK_MAPPING, por ejemplo:\n",
        "              {'nasion': (x, y), 'pronasale': (x, y), ...}\n",
        "              Si no se detecta ningún rostro → None\n",
        "    \"\"\"\n",
        "    print(\"\\n PASO 2: Detectando landmarks faciales...\")\n",
        "\n",
        "    # --- 1️ Convertir BGR a RGB (requisito para MediaPipe) ---\n",
        "    imagen_rgb = cv2.cvtColor(imagen, cv2.COLOR_BGR2RGB)\n",
        "    alto, ancho = imagen_rgb.shape[:2]\n",
        "\n",
        "    # --- 2️ Procesar la imagen con MediaPipe Face Mesh ---\n",
        "    resultados = face_mesh.process(imagen_rgb)\n",
        "\n",
        "    if not resultados.multi_face_landmarks:\n",
        "        print(\" No se detectó ningún rostro en la imagen.\")\n",
        "        return None\n",
        "\n",
        "    if len(resultados.multi_face_landmarks) > 1:\n",
        "        print(\" Se detectaron múltiples rostros. Se tomará el primero.\")\n",
        "\n",
        "    # --- 3️ Extraer landmarks del primer rostro detectado ---\n",
        "    face_landmarks = resultados.multi_face_landmarks[0]\n",
        "    landmarks_coords = {}\n",
        "\n",
        "    # --- 4️ Convertir landmarks normalizados a coordenadas en píxeles ---\n",
        "    for nombre_punto, indice_mp in LANDMARK_MAPPING.items():\n",
        "        if indice_mp < len(face_landmarks.landmark):\n",
        "            landmark = face_landmarks.landmark[indice_mp]\n",
        "            x_px = int(landmark.x * ancho)\n",
        "            y_px = int(landmark.y * alto)\n",
        "            landmarks_coords[nombre_punto] = (x_px, y_px)\n",
        "\n",
        "    print(f\" Landmarks detectados: {len(landmarks_coords)} puntos\")\n",
        "\n",
        "    # --- 5️ Mostrar algunos puntos clave (opcional) ---\n",
        "    puntos_clave = ['nasion', 'pronasale', 'ectocanthion_L', 'ectocanthion_R']\n",
        "    for punto in puntos_clave:\n",
        "        if punto in landmarks_coords:\n",
        "            x, y = landmarks_coords[punto]\n",
        "            print(f\"   📍 {punto}: ({x}, {y})\")\n",
        "\n",
        "    return landmarks_coords\n"
      ],
      "metadata": {
        "id": "ytrLfNM_6d5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# FUNCIÓN: CALCULAR MEDIDAS MORFOMÉTRICAS EN PÍXELES\n",
        "# ============================================================================\n",
        "\n",
        "import math\n",
        "\n",
        "def calcular_medidas(landmarks):\n",
        "    \"\"\"\n",
        "    Calcula distancias morfométricas (en píxeles) entre puntos anatómicos\n",
        "    definidos en MEDIDAS_OSTEOFORENSES.\n",
        "\n",
        "    Parámetros:\n",
        "        landmarks (dict): Diccionario con coordenadas de landmarks,\n",
        "                          ej: {'nasion': (x,y), 'pronasale': (x,y)}\n",
        "\n",
        "    Retorna:\n",
        "        dict: Un diccionario con las medidas calculadas, cada entrada incluye:\n",
        "              - descripción\n",
        "              - nombre de los puntos A y B\n",
        "              - coordenadas de A y B\n",
        "              - distancia en píxeles\n",
        "    \"\"\"\n",
        "    print(\"\\n PASO 3: Calculando medidas morfométricas...\")\n",
        "\n",
        "    # --- 1️Función interna para calcular distancia euclidiana ---\n",
        "    def distancia_euclidiana(punto1, punto2):\n",
        "        return math.sqrt(\n",
        "            (punto1[0] - punto2[0])**2 +\n",
        "            (punto1[1] - punto2[1])**2\n",
        "        )\n",
        "\n",
        "    medidas_calculadas = {}\n",
        "    medidas_exitosas = 0\n",
        "\n",
        "    # --- 2️ Calcular cada medida definida en MEDIDAS_OSTEOFORENSES ---\n",
        "    for codigo_medida, (punto_a, punto_b, descripcion) in MEDIDAS_OSTEOFORENSES.items():\n",
        "        if punto_a in landmarks and punto_b in landmarks:\n",
        "            try:\n",
        "                distancia_px = distancia_euclidiana(\n",
        "                    landmarks[punto_a], landmarks[punto_b])\n",
        "\n",
        "                # Guardar resultados en el diccionario\n",
        "                medidas_calculadas[codigo_medida] = {\n",
        "                    'descripcion': descripcion,\n",
        "                    'punto_a': punto_a,\n",
        "                    'punto_b': punto_b,\n",
        "                    'coord_a': landmarks[punto_a],\n",
        "                    'coord_b': landmarks[punto_b],\n",
        "                    'distancia_px': round(distancia_px, 3)\n",
        "                }\n",
        "                medidas_exitosas += 1\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\" Error calculando {codigo_medida}: {e}\")\n",
        "        else:\n",
        "            # Si faltan puntos para la medida, mostrar alerta\n",
        "            puntos_faltantes = []\n",
        "            if punto_a not in landmarks:\n",
        "                puntos_faltantes.append(punto_a)\n",
        "            if punto_b not in landmarks:\n",
        "                puntos_faltantes.append(punto_b)\n",
        "            print(f\" {codigo_medida}: Faltan puntos {puntos_faltantes}\")\n",
        "\n",
        "    print(f\" Medidas calculadas con éxito: {medidas_exitosas}/{len(MEDIDAS_OSTEOFORENSES)}\")\n",
        "\n",
        "    # --- 3️ Mostrar medidas principales (opcional) ---\n",
        "    medidas_principales = ['ex_ex', 'n_sn', 'al_al', 'ch_ch']\n",
        "    print(\"📏 Medidas principales (en píxeles):\")\n",
        "    for medida in medidas_principales:\n",
        "        if medida in medidas_calculadas:\n",
        "            valor = medidas_calculadas[medida]['distancia_px']\n",
        "            desc = medidas_calculadas[medida]['descripcion']\n",
        "            print(f\"   • {medida}: {valor} px → {desc}\")\n",
        "\n",
        "    return medidas_calculadas\n"
      ],
      "metadata": {
        "id": "jkTH32xW62Jt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# FUNCIÓN: CONVERTIR MEDIDAS DE PÍXELES A MILÍMETROS\n",
        "# ============================================================================\n",
        "\n",
        "def convertir_a_milimetros(medidas_px, referencia_mm=96):\n",
        "    \"\"\"\n",
        "    Convierte las medidas calculadas en píxeles a milímetros usando\n",
        "    una referencia conocida (por defecto, la distancia bi-ectocanthal = 96 mm).\n",
        "\n",
        "    Parámetros:\n",
        "        medidas_px (dict): Diccionario de medidas en píxeles generado por calcular_medidas().\n",
        "        referencia_mm (float): Valor en milímetros de la distancia bi-ectocanthal usada para calibrar.\n",
        "\n",
        "    Retorna:\n",
        "        tuple:\n",
        "          - medidas_mm (dict): Medidas con distancias convertidas a mm.\n",
        "          - factor_escala (float): Factor de conversión mm/px.\n",
        "    \"\"\"\n",
        "    print(\"\\n PASO 4: Convirtiendo medidas de píxeles a milímetros...\")\n",
        "\n",
        "    # --- 1️ Verificar medida de calibración (bi-ectocanthal) ---\n",
        "    if 'ex_ex' not in medidas_px:\n",
        "        print(\" No se encontró la medida bi-ectocanthal (ex_ex) para calibración.\")\n",
        "        return None, None\n",
        "\n",
        "    # --- 2️ Calcular factor de escala mm/px ---\n",
        "    ex_ex_px = medidas_px['ex_ex']['distancia_px']\n",
        "    factor_escala = referencia_mm / ex_ex_px  # milímetros por píxel\n",
        "\n",
        "    print(\"📐 Parámetros de calibración:\")\n",
        "    print(f\"   📏 Bi-ectocanthal medido: {ex_ex_px} píxeles\")\n",
        "    print(f\"   📏 Bi-ectocanthal referencia: {referencia_mm} mm\")\n",
        "    print(f\"   🔢 Factor de escala: {factor_escala:.6f} mm/px\")\n",
        "\n",
        "    # --- 3️ Convertir todas las medidas a milímetros ---\n",
        "    medidas_mm = {}\n",
        "    for codigo_medida, datos in medidas_px.items():\n",
        "        distancia_mm = datos['distancia_px'] * factor_escala\n",
        "\n",
        "        # Copiamos los datos originales y añadimos campos de milímetros\n",
        "        medidas_mm[codigo_medida] = {\n",
        "            **datos,\n",
        "            'distancia_mm': round(distancia_mm, 2),\n",
        "            'factor_escala_mm_px': round(factor_escala, 6),\n",
        "            'referencia_calibracion': f\"bi-ectocanthal = {referencia_mm} mm\"\n",
        "        }\n",
        "\n",
        "    print(f\" Conversión completada: {len(medidas_mm)} medidas convertidas.\")\n",
        "\n",
        "    # --- 4️ Mostrar medidas clave en milímetros ---\n",
        "    medidas_clave = ['ex_ex', 'n_sn', 'al_al', 'ch_ch', 'zy_zy', 'g_gn']\n",
        "    print(\"📏 Medidas principales (milímetros):\")\n",
        "    for medida in medidas_clave:\n",
        "        if medida in medidas_mm:\n",
        "            valor_mm = medidas_mm[medida]['distancia_mm']\n",
        "            desc = medidas_mm[medida]['descripcion']\n",
        "            print(f\"   • {medida}: {valor_mm} mm → {desc}\")\n",
        "\n",
        "    return medidas_mm, factor_escala\n"
      ],
      "metadata": {
        "id": "xX4-BvLv7EFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "#  FUNCIÓN: CREAR VISUALIZACIÓN DE LANDMARKS Y MEDICIONES\n",
        "# ============================================================================\n",
        "def crear_visualizacion(imagen, landmarks, medidas):\n",
        "    \"\"\"\n",
        "    Genera una visualización comparativa entre:\n",
        "      - Imagen original\n",
        "      - Imagen con puntos (landmarks) y líneas de medición superpuestos.\n",
        "\n",
        "    Parámetros:\n",
        "        imagen (np.ndarray): Imagen original en formato BGR.\n",
        "        landmarks (dict): Diccionario {nombre_punto: (x, y)} con coordenadas.\n",
        "        medidas (dict): Diccionario con datos de medidas (px y mm).\n",
        "\n",
        "    Retorna:\n",
        "        img_viz (np.ndarray): Imagen con landmarks y mediciones dibujadas.\n",
        "    \"\"\"\n",
        "    print(\"\\n PASO 5: Creando visualización...\")\n",
        "\n",
        "    # --- 1️ Crear copia de la imagen para no modificar la original ---\n",
        "    img_viz = imagen.copy()\n",
        "\n",
        "    # --- 2️ Dibujar LANDMARKS ---\n",
        "    for nombre, (x, y) in landmarks.items():\n",
        "        # Punto verde (centro)\n",
        "        cv2.circle(img_viz, (x, y), 4, (0, 255, 0), -1)\n",
        "        # Borde negro para resaltar\n",
        "        cv2.circle(img_viz, (x, y), 4, (0, 0, 0), 1)\n",
        "        # Etiqueta con primeras 4 letras del punto\n",
        "        cv2.putText(img_viz, nombre[:4], (x + 6, y - 6),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.35, (255, 255, 255), 1)\n",
        "        cv2.putText(img_viz, nombre[:4], (x + 5, y - 5),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 0, 0), 1)\n",
        "\n",
        "    # --- 3️ Definir colores para MEDIDAS PRINCIPALES ---\n",
        "    medidas_principales = {\n",
        "        'ex_ex': (255, 0, 0),      # Rojo - referencia\n",
        "        'n_sn': (0, 255, 0),       # Verde - altura nasal\n",
        "        'al_al': (0, 0, 255),      # Azul - ancho nasal\n",
        "        'ch_ch': (255, 255, 0),    # Amarillo - ancho boca\n",
        "        'zy_zy': (255, 0, 255),    # Magenta - bizigomático\n",
        "        'g_gn': (0, 255, 255)      # Cian - altura facial\n",
        "    }\n",
        "\n",
        "    # --- 4️ Dibujar líneas y textos de MEDICIONES ---\n",
        "    for medida, color in medidas_principales.items():\n",
        "        if medida in medidas:\n",
        "            datos = medidas[medida]\n",
        "            pt1 = datos['coord_a']\n",
        "            pt2 = datos['coord_b']\n",
        "\n",
        "            # Línea entre puntos\n",
        "            cv2.line(img_viz, pt1, pt2, color, 2)\n",
        "\n",
        "            # Calcular punto medio para colocar texto\n",
        "            punto_medio = ((pt1[0] + pt2[0]) // 2,\n",
        "                           (pt1[1] + pt2[1]) // 2)\n",
        "            texto_medida = f\"{datos['distancia_mm']} mm\"\n",
        "\n",
        "            # Fondo blanco para el texto\n",
        "            (w_texto, h_texto), _ = cv2.getTextSize(texto_medida,\n",
        "                                                    cv2.FONT_HERSHEY_SIMPLEX, 0.4, 1)\n",
        "            cv2.rectangle(img_viz,\n",
        "                          (punto_medio[0] - w_texto // 2 - 2, punto_medio[1] - h_texto - 2),\n",
        "                          (punto_medio[0] + w_texto // 2 + 2, punto_medio[1] + 2),\n",
        "                          (255, 255, 255), -1)\n",
        "\n",
        "            # Texto negro encima\n",
        "            cv2.putText(img_viz, texto_medida,\n",
        "                        (punto_medio[0] - w_texto // 2, punto_medio[1]),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 0), 1)\n",
        "\n",
        "    # --- 5️ Mostrar comparativa: Original vs Analizada ---\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
        "\n",
        "    # Imagen original\n",
        "    ax1.imshow(cv2.cvtColor(imagen, cv2.COLOR_BGR2RGB))\n",
        "    ax1.set_title(\"Imagen Original\", fontsize=14, fontweight='bold')\n",
        "    ax1.axis('off')\n",
        "\n",
        "    # Imagen con análisis\n",
        "    ax2.imshow(cv2.cvtColor(img_viz, cv2.COLOR_BGR2RGB))\n",
        "    ax2.set_title(\"Análisis Osteoforense - Landmarks y Mediciones\",\n",
        "                  fontsize=14, fontweight='bold')\n",
        "    ax2.axis('off')\n",
        "\n",
        "    fig.suptitle(\"Análisis Osteoforense - Hash: 0aad2507...68b5\",\n",
        "                 fontsize=16, fontweight='bold')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # --- 6️ Guardar la visualización ---\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    ruta_viz = f\"{proyecto_path}/resultados/visualizacion_{timestamp}.jpg\"\n",
        "    cv2.imwrite(ruta_viz, img_viz)\n",
        "    print(f\" Visualización guardada en: {ruta_viz}\")\n",
        "\n",
        "    return img_viz\n"
      ],
      "metadata": {
        "id": "-nVrFXVZ7Q90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "#  FUNCIÓN: EXPORTAR BASE DE DATOS DE ANÁLISIS OSTEFORENSE\n",
        "# ============================================================================\n",
        "def exportar_base_datos(landmarks, medidas_mm, factor_escala, filename):\n",
        "    \"\"\"\n",
        "    Exporta los resultados del análisis osteoforense en varios formatos (Excel, CSV, JSON).\n",
        "\n",
        "    Parámetros:\n",
        "        landmarks (dict): Puntos anatómicos detectados {nombre: (x, y)}.\n",
        "        medidas_mm (dict): Medidas morfométricas ya convertidas a milímetros.\n",
        "        factor_escala (float): Factor mm/px usado en la conversión.\n",
        "        filename (str): Nombre del archivo original analizado.\n",
        "\n",
        "    Retorna:\n",
        "        pd.DataFrame: DataFrame con todas las medidas calculadas.\n",
        "    \"\"\"\n",
        "    print(\"\\n PASO 6: Exportando base de datos...\")\n",
        "\n",
        "    # === 1️ Preparar metadatos ===\n",
        "    timestamp = datetime.now()\n",
        "    hash_imagen = \"0aad2507592c642223603f2e46cf1bdc601f8136fd5e7a4cc4cec59f844a68b5\"\n",
        "\n",
        "    # === 2️ Convertir medidas a filas de DataFrame ===\n",
        "    filas_datos = []\n",
        "    for codigo_medida, datos in medidas_mm.items():\n",
        "        fila = {\n",
        "            'timestamp': timestamp,\n",
        "            'hash_imagen': hash_imagen,\n",
        "            'archivo_original': filename,\n",
        "            'codigo_medida': codigo_medida,\n",
        "            'descripcion': datos['descripcion'],\n",
        "            'punto_a': datos['punto_a'],\n",
        "            'punto_b': datos['punto_b'],\n",
        "            'coord_a_x': datos['coord_a'][0],\n",
        "            'coord_a_y': datos['coord_a'][1],\n",
        "            'coord_b_x': datos['coord_b'][0],\n",
        "            'coord_b_y': datos['coord_b'][1],\n",
        "            'distancia_px': datos['distancia_px'],\n",
        "            'distancia_mm': datos['distancia_mm'],\n",
        "            'factor_escala_mm_px': datos['factor_escala_mm_px'],\n",
        "            'referencia_calibracion': datos['referencia_calibracion']\n",
        "        }\n",
        "        filas_datos.append(fila)\n",
        "\n",
        "    # Crear DataFrame principal con medidas\n",
        "    df_resultados = pd.DataFrame(filas_datos)\n",
        "\n",
        "    # === 3️ Preparar nombres de archivos ===\n",
        "    base_nombre = f\"analisis_osteoforense_{timestamp.strftime('%Y%m%d_%H%M%S')}\"\n",
        "    ruta_excel = f\"{proyecto_path}/resultados/{base_nombre}.xlsx\"\n",
        "    ruta_csv = f\"{proyecto_path}/resultados/{base_nombre}.csv\"\n",
        "    ruta_json = f\"{proyecto_path}/resultados/{base_nombre}.json\"\n",
        "\n",
        "    # === 4️ Exportar Excel con 3 hojas ===\n",
        "    with pd.ExcelWriter(ruta_excel, engine='openpyxl') as writer:\n",
        "        # Hoja principal con medidas\n",
        "        df_resultados.to_excel(writer, sheet_name='Medidas_Completas', index=False)\n",
        "\n",
        "        # Hoja de landmarks\n",
        "        df_landmarks = pd.DataFrame([\n",
        "            {'landmark': nombre, 'x_px': coord[0], 'y_px': coord[1]}\n",
        "            for nombre, coord in landmarks.items()\n",
        "        ])\n",
        "        df_landmarks.to_excel(writer, sheet_name='Landmarks', index=False)\n",
        "\n",
        "        # Hoja resumen solo con medida y distancia mm\n",
        "        df_resumen = df_resultados[['codigo_medida', 'descripcion', 'distancia_mm']].copy()\n",
        "        df_resumen.to_excel(writer, sheet_name='Resumen_Medidas', index=False)\n",
        "\n",
        "    # === 5️ Exportar CSV ===\n",
        "    df_resultados.to_csv(ruta_csv, index=False, encoding='utf-8')\n",
        "\n",
        "    # === 6️ Exportar JSON ===\n",
        "    datos_json = {\n",
        "        'metadatos': {\n",
        "            'timestamp': timestamp.isoformat(),\n",
        "            'hash_imagen': hash_imagen,\n",
        "            'archivo_original': filename,\n",
        "            'total_landmarks': len(landmarks),\n",
        "            'total_medidas': len(medidas_mm),\n",
        "            'factor_escala_mm_px': factor_escala,\n",
        "            'referencia_calibracion': 'bi-ectocanthal = 96mm'\n",
        "        },\n",
        "        'landmarks': {nombre: {'x_px': coord[0], 'y_px': coord[1]}\n",
        "                      for nombre, coord in landmarks.items()},\n",
        "        'medidas_morfometricas': medidas_mm\n",
        "    }\n",
        "\n",
        "    with open(ruta_json, 'w', encoding='utf-8') as f:\n",
        "        json.dump(datos_json, f, indent=2, ensure_ascii=False, default=str)\n",
        "\n",
        "    # === 7️ Mostrar reporte en consola ===\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\" ANÁLISIS COMPLETADO - REPORTE FINAL\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\" Imagen analizada: {filename}\")\n",
        "    print(f\" Hash: {hash_imagen}\")\n",
        "    print(f\" Timestamp: {timestamp.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "    print(f\"📍 Landmarks detectados: {len(landmarks)}\")\n",
        "    print(f\"📏 Medidas calculadas: {len(medidas_mm)}\")\n",
        "    print(f\"🔢 Factor de escala: {factor_escala:.6f} mm/px\")\n",
        "\n",
        "    print(f\"\\n Archivos exportados:\")\n",
        "    print(f\"    Excel: {base_nombre}.xlsx\")\n",
        "    print(f\"    CSV: {base_nombre}.csv\")\n",
        "    print(f\"    JSON: {base_nombre}.json\")\n",
        "\n",
        "    # Mostrar algunas medidas clave en consola\n",
        "    print(f\"\\n📏 MEDIDAS MORFOMÉTRICAS FINALES:\")\n",
        "    medidas_reporte = ['g_gn', 'zy_zy', 'go_go', 'n_sn', 'al_al', 'ex_ex', 'ch_ch']\n",
        "    for medida in medidas_reporte:\n",
        "        if medida in medidas_mm:\n",
        "            valor = medidas_mm[medida]['distancia_mm']\n",
        "            descripcion = medidas_mm[medida]['descripcion']\n",
        "            print(f\"    {medida}: {valor} mm - {descripcion}\")\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    return df_resultados\n"
      ],
      "metadata": {
        "id": "Z45gHn4H8NDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# FUNCIÓN PRINCIPAL: EJECUTAR ANÁLISIS COMPLETO\n",
        "# ============================================================================\n",
        "def ejecutar_analisis_completo():\n",
        "    \"\"\"\n",
        "    Ejecuta todo el flujo del análisis osteoforense de una imagen:\n",
        "    1. Carga de imagen\n",
        "    2. Detección de landmarks\n",
        "    3. Cálculo de medidas en píxeles\n",
        "    4. Conversión de medidas a milímetros\n",
        "    5. Visualización gráfica del análisis\n",
        "    6. Exportación de resultados a base de datos (Excel, CSV, JSON)\n",
        "\n",
        "    Retorna:\n",
        "        bool: True si todo se ejecutó correctamente, False si hubo algún error.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\n INICIANDO ANÁLISIS OSTEOFORENSE - IMAGEN INDIVIDUAL\")\n",
        "    print(\" Hash de referencia: 0aad2507592c642223603f2e46cf1bdc601f8136fd5e7a4cc4cec59f844a68b5\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    try:\n",
        "        # === 1️ Paso 1: Cargar imagen ===\n",
        "        imagen, filename = cargar_imagen()\n",
        "        if imagen is None:\n",
        "            print(\" No se pudo cargar la imagen. Proceso detenido.\")\n",
        "            return False\n",
        "\n",
        "        # === 2️ Paso 2: Detectar landmarks ===\n",
        "        landmarks = detectar_landmarks(imagen)\n",
        "        if landmarks is None:\n",
        "            print(\" No se pudieron detectar landmarks. Proceso detenido.\")\n",
        "            return False\n",
        "\n",
        "        # === 3️ Paso 3: Calcular medidas en píxeles ===\n",
        "        medidas_px = calcular_medidas(landmarks)\n",
        "        if not medidas_px:\n",
        "            print(\" No se pudieron calcular medidas. Proceso detenido.\")\n",
        "            return False\n",
        "\n",
        "        # === 4️ Paso 4: Convertir medidas a milímetros ===\n",
        "        medidas_mm, factor_escala = convertir_a_milimetros(medidas_px)\n",
        "        if medidas_mm is None:\n",
        "            print(\" No se pudo realizar calibración. Proceso detenido.\")\n",
        "            return False\n",
        "\n",
        "        # === 5️ Paso 5: Crear visualización del análisis ===\n",
        "        crear_visualizacion(imagen, landmarks, medidas_mm)\n",
        "\n",
        "        # === 6️ Paso 6: Exportar resultados a base de datos ===\n",
        "        df_resultados = exportar_base_datos(landmarks, medidas_mm, factor_escala, filename)\n",
        "\n",
        "        # ===  Finalización ===\n",
        "        print(\"\\n ¡ANÁLISIS COMPLETADO EXITOSAMENTE!\")\n",
        "        print(\" Resultados almacenados y visualización generada correctamente.\")\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        # Manejo de errores críticos\n",
        "        print(\"\\n ERROR CRÍTICO DURANTE EL ANÁLISIS\")\n",
        "        print(f\" Detalles del error: {e}\")\n",
        "        return False\n"
      ],
      "metadata": {
        "id": "m-Ab77bD9LkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "#  EJECUTAR ANÁLISIS COMPLETO DESDE TERMINAL O NOTEBOOK\n",
        "# ============================================================================\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\n Iniciando ejecución completa del análisis osteoforense...\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    exito = ejecutar_analisis_completo()  # Llama a la función principal\n",
        "\n",
        "    if exito:\n",
        "        print(\"\\n PROCESO FINALIZADO CORRECTAMENTE\")\n",
        "        print(\" Todos los resultados, gráficos y bases de datos se han guardado en tu Google Drive\")\n",
        "        print(\" Revisa la carpeta 'Analisis_Osteoforense/resultados' para ver los archivos generados.\")\n",
        "    else:\n",
        "        print(\"\\n PROCESO FINALIZADO CON ERRORES\")\n",
        "        print(\" Verifica que la imagen cumpla estas condiciones:\")\n",
        "        print(\"   - Contenga un rostro claramente visible\")\n",
        "        print(\"   - Buena iluminación y calidad de imagen\")\n",
        "        print(\"   - Puntos faciales detectables (sin accesorios que los tapen)\")\n",
        "        print(\"\\n Vuelve a ejecutar el análisis una vez verificado todo.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "id": "wVc_m7w99rFv",
        "outputId": "ef50c7c0-76aa-451b-919d-b2e73d322bdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Iniciando ejecución completa del análisis osteoforense...\n",
            "================================================================================\n",
            "\n",
            " INICIANDO ANÁLISIS OSTEOFORENSE - IMAGEN INDIVIDUAL\n",
            " Hash de referencia: 0aad2507592c642223603f2e46cf1bdc601f8136fd5e7a4cc4cec59f844a68b5\n",
            "================================================================================\n",
            "PASO 1: Cargar imagen para análisis\n",
            "Selecciona la imagen que deseas analizar:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fea11a60-20f6-4925-a6d3-201d7d18f4dd\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fea11a60-20f6-4925-a6d3-201d7d18f4dd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 39f47eace8589a2f2730bbd1a4cd46daf6422e324890263690f38c6f424616f5.png to 39f47eace8589a2f2730bbd1a4cd46daf6422e324890263690f38c6f424616f5.png\n",
            "Imagen cargada exitosamente.\n",
            "   📏 Dimensiones: 369 x 369 píxeles\n",
            "Archivo: 39f47eace8589a2f2730bbd1a4cd46daf6422e324890263690f38c6f424616f5.png\n",
            "Imagen guardada en: /content/drive/MyDrive/Analisis_Osteoforense/imagenes/0aad2507592c642223603f2e46cf1bdc601f8136fd5e7a4cc4cec59f844a68b5.jpg\n",
            "\n",
            " PASO 2: Detectando landmarks faciales...\n",
            " Landmarks detectados: 21 puntos\n",
            "   📍 nasion: (144, 164)\n",
            "   📍 pronasale: (144, 223)\n",
            "   📍 ectocanthion_L: (91, 163)\n",
            "   📍 ectocanthion_R: (216, 157)\n",
            "\n",
            " ERROR CRÍTICO DURANTE EL ANÁLISIS\n",
            " Detalles del error: name 'calcular_medidas' is not defined\n",
            "\n",
            " PROCESO FINALIZADO CON ERRORES\n",
            " Verifica que la imagen cumpla estas condiciones:\n",
            "   - Contenga un rostro claramente visible\n",
            "   - Buena iluminación y calidad de imagen\n",
            "   - Puntos faciales detectables (sin accesorios que los tapen)\n",
            "\n",
            " Vuelve a ejecutar el análisis una vez verificado todo.\n"
          ]
        }
      ]
    }
  ]
}